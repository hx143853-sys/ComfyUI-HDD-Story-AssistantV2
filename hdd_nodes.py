import os
import json
import folder_paths
import re
import pandas as pd
from openai import OpenAI
try: import docx 
except ImportError: docx = None

# å¼ºåˆ¶å…³é—­ä»£ç† (è§£å†³ AutoDL è¿æ¥é˜¿é‡Œäº‘æŠ¥é”™)
os.environ.pop("http_proxy", None)
os.environ.pop("https_proxy", None)

# ç‰ˆæœ¬æ ‡è¯†: V1.5 - å¼ºåˆ¶ä¸­æ–‡æ ‡ç­¾

# ==============================================================================
# è¾…åŠ©å‡½æ•°
# ==============================================================================
def clean_json_string(json_str):
    try:
        start = json_str.find('{')
        end = json_str.rfind('}')
        if start != -1 and end != -1:
            return json_str[start:end+1]
        return "{}"
    except: return "{}"

# ==============================================================================
# èŠ‚ç‚¹ 1: å‰§æœ¬è§’è‰²åˆ†æ (HDD_Script_Character_Analysis)
# ==============================================================================
class HDD_Script_Character_Analysis:
    def __init__(self): pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "file_name": ("STRING", {"default": "è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¸Šä¼ æ–‡ä»¶...", "multiline": False, "label": "ä¸Šä¼ å‰§æœ¬æ–‡ä»¶ (Txt/Docx)"}),
                "model_select": ([
                    "qwen3-max (æœ€æ–°æ­£å¼ç‰ˆ)", 
                    "qwen3-max-preview (æ€è€ƒæ¨¡å¼)", 
                    "qwen3-max-2025-09-23 (å¿«ç…§ç‰ˆæœ¬)"
                ], {"label": "AIæ¨¡å‹é€‰æ‹©"}),
                "api_key": ("STRING", {"multiline": False, "default": "", "label": "ğŸ”‘ é˜¿é‡Œäº‘APIå¯†é’¥ (sk-...)"}),
                
                # æµ‹è¯•åŠŸèƒ½
                "enable_test_mode": ("BOOLEAN", {"default": False, "label": "ğŸ› ï¸ å¯ç”¨æµ‹è¯•æ¨¡å¼ (å¿½ç•¥æ–‡ä»¶ï¼Œç›´æ¥æµ‹è¯•AI)"}),
                "test_input_text": ("STRING", {"default": "ä½ æ˜¯è°ï¼Ÿ", "multiline": True, "label": "æµ‹è¯•æé—®å†…å®¹"}),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("è§’è‰²è®¾å®šJSON",)
    FUNCTION = "analyze_characters"
    CATEGORY = "HDD/Story"

    def analyze_characters(self, file_name, model_select, api_key, enable_test_mode, test_input_text):
        if not api_key: return ("{}",)
        
        # æ¨¡å‹IDå¤„ç†
        model_id = "qwen3-max"
        if "preview" in model_select: model_id = "qwen3-max-preview"
        elif "2025-09-23" in model_select: model_id = "qwen3-max-2025-09-23"

        client = OpenAI(api_key=api_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")

        # --- æµ‹è¯•æ¨¡å¼ ---
        if enable_test_mode and test_input_text.strip():
            try:
                print(f"ğŸ› ï¸ [è§’è‰²åˆ†æ] æµ‹è¯•æ¨¡å¼: {model_id}")
                resp = client.chat.completions.create(model=model_id, messages=[{"role": "user", "content": test_input_text}])
                return (resp.choices[0].message.content,)
            except Exception as e: return (json.dumps({"æµ‹è¯•é”™è¯¯": str(e)}),)

        # --- æ­£å¸¸é€»è¾‘ ---
        input_dir = folder_paths.get_input_directory()
        full_path = os.path.join(input_dir, os.path.basename(file_name))
        if not os.path.exists(full_path): full_path = file_name
        
        text_content = ""
        try:
            if full_path.endswith(('.xlsx', '.xls', '.csv')):
                if full_path.endswith('.csv'): df = pd.read_csv(full_path)
                else: df = pd.read_excel(full_path)
                text_content = df.to_string()
            elif full_path.endswith('.docx'):
                if docx is None: return (json.dumps({"é”™è¯¯": "éœ€å®‰è£…python-docxåº“"}),)
                doc = docx.Document(full_path)
                text_content = "\n".join([p.text for p in doc.paragraphs])
            else:
                with open(full_path, 'r', encoding='utf-8') as f: text_content = f.read()
        except Exception as e: return (json.dumps({"é”™è¯¯": str(e)}),)

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‰§æœ¬è§’è‰²åˆ†æå¸ˆã€‚æå–å»æ–‡æœ¬ã€åˆ†é•œè¡¨æ ¼ä¸­ä¸»è¦è§’è‰²çš„åå­—å’Œå¤–è²Œç‰¹å¾ï¼Œå¹¶å°†å…¶è½¬æ¢æˆé€‚åˆQwenç­‰è‡ªç„¶è¯­è¨€çš„æ¨¡å‹çš„ä¸­æ–‡æç¤ºè¯ï¼Œæç¤ºè¯ä¸¾ä¾‹â€œä¸€ä¸ªæœ‰ç€é»‘è‰²å§¬å¼çŸ­å‘çš„å°‘å¥³ï¼Œå¥¹æœ‰ç€çº¢è‰²çš„çœ¼ç›ï¼Œç©¿ç€æœ‰ç€å¤æ‚èŠ±çº¹çš„çº¢è‰²æ—¥å¼å’Œæœï¼Œç©¿ç€ç™½è¢œå’Œè¤è‰²çŸ­é´â€ã€‚
è¦æ±‚ï¼šè¾“å‡ºæ ‡å‡†JSONæ ¼å¼ï¼ŒKeyä¸ºè§’è‰²åï¼ŒValueä¸ºå¤–è²Œæè¿°ã€‚ä¸è¦è¾“å‡ºMarkdownæ ‡è®°ã€‚"""

        try:
            resp = client.chat.completions.create(
                model=model_id,
                messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": text_content[:30000]}]
            )
            return (clean_json_string(resp.choices[0].message.content),)
        except Exception as e: return (json.dumps({"ç³»ç»Ÿé”™è¯¯": str(e)}),)


# ==============================================================================
# èŠ‚ç‚¹ 2: åˆ†é•œè½¬ç»˜å›¾ (HDD_Storyboard_Prompt_Gen)
# ==============================================================================
class HDD_Storyboard_Prompt_Gen:
    def __init__(self): pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "file_name": ("STRING", {"default": "è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¸Šä¼ æ–‡ä»¶...", "multiline": False, "label": "ä¸Šä¼ åˆ†é•œ/å°è¯´æ–‡ä»¶"}),
                "input_mode": (["åˆ†é•œè¡¨æ ¼æ¨¡å¼ (Excel/CSV - ä¸€è¡Œä¸€é•œ)", "å°è¯´å‰§æœ¬æ¨¡å¼ (Txt/Word - è‡ªåŠ¨åˆ†é•œ)"], {"label": "è¾“å…¥æ¨¡å¼é€‰æ‹©"}),
                "model_select": ([
                    "qwen3-max (æœ€æ–°æ­£å¼ç‰ˆ)", 
                    "qwen3-max-preview (æ€è€ƒæ¨¡å¼)", 
                    "qwen3-max-2025-09-23 (å¿«ç…§ç‰ˆæœ¬)"
                ], {"label": "AIæ¨¡å‹é€‰æ‹©"}),
                "api_key": ("STRING", {"multiline": False, "default": "", "label": "ğŸ”‘ é˜¿é‡Œäº‘APIå¯†é’¥"}), 
                "style_tag": ([
                    "ç°ä»£éƒ½å¸‚", "æœªæ¥ç§‘å¹»", "å¤ä»£æ‚¬ç–‘", "ä¸­å¼ææ€–",
                    "å¤ä»£å”¯ç¾", "å¤é£ä»™ä¾ ", "èµ›åšæœ‹å…‹", "æœ«ä¸–åºŸåœŸ", 
                    "æ—¥ç³»æ ¡å›­", "æš—é»‘å“¥ç‰¹", "ä¸­ä¸–çºªç„å¹»", "è’¸æ±½æœ‹å…‹", "å…‹è‹é²ç¥è¯"
                ], {"label": "ç”»é¢é£æ ¼"}),
                "character_config": ("STRING", {"default": "{}", "multiline": True, "label": "è§’è‰²è®¾å®š (æ‰‹åŠ¨è¾“å…¥)"}),
                
                # å¼ºåˆ¶ä¸­æ–‡æ ‡ç­¾
                "enable_dialogue": ("BOOLEAN", {"default": True, "label": "å¯ç”¨å°è¯ç”Ÿæˆ"}),
                "enable_sfx": ("BOOLEAN", {"default": False, "label": "å¯ç”¨éŸ³æ•ˆç”Ÿæˆ"}),
                "enable_camera_move": ("BOOLEAN", {"default": False, "label": "ä¿ç•™è¿é•œæè¿°"}),
                
                # æµ‹è¯•åŠŸèƒ½
                "enable_test_mode": ("BOOLEAN", {"default": False, "label": "ğŸ› ï¸ å¯ç”¨æµ‹è¯•æ¨¡å¼"}),
                "test_input_text": ("STRING", {"default": "ä½ æ˜¯è°ï¼Ÿ", "multiline": True, "label": "æµ‹è¯•æé—®å†…å®¹"}),
            },
            "optional": {
                "external_char_json": ("STRING", {"forceInput": True, "label": "è‡ªåŠ¨è§’è‰²æ•°æ® (è¿æ¥åˆ†æèŠ‚ç‚¹)"}),
            }
        }

    RETURN_TYPES = ("STRING", "LIST", "STRING", "STRING")
    RETURN_NAMES = ("å®Œæ•´æç¤ºè¯æ–‡æœ¬", "æç¤ºè¯åˆ—è¡¨", "AIæ€è€ƒè¿‡ç¨‹", "APIè¿”å›åŸå§‹ä¿¡æ¯")
    FUNCTION = "process_storyboard"
    CATEGORY = "HDD/Story"

    def process_storyboard(self, file_name, input_mode, model_select, api_key, style_tag, character_config, enable_dialogue, enable_sfx, enable_camera_move, enable_test_mode, test_input_text, external_char_json=None):
        model_id = "qwen3-max"
        if "preview" in model_select: model_id = "qwen3-max-preview"
        elif "2025-09-23" in model_select: model_id = "qwen3-max-2025-09-23"

        # --- æµ‹è¯•æ¨¡å¼ ---
        if enable_test_mode and test_input_text.strip():
            print(f"ğŸ› ï¸ [åˆ†é•œç»˜å›¾] æµ‹è¯•æ¨¡å¼: {model_id}")
            res, thought = self._call_qwen(api_key, model_id, "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚", test_input_text)
            return (res, [res], f"æ€è€ƒè¿‡ç¨‹:\n{thought}", f"åŸå§‹è¾“å‡º: {res}")

        full_thought_process = []
        chars = {}
        try: chars.update(json.loads(character_config))
        except: pass
        if external_char_json and external_char_json.strip():
            try: chars.update(json.loads(clean_json_string(external_char_json)))
            except: pass

        input_dir = folder_paths.get_input_directory()
        clean_name = os.path.basename(file_name)
        full_path = os.path.join(input_dir, clean_name)
        if not os.path.exists(full_path): full_path = file_name 

        raw_content_list = [] 
        if "è¡¨æ ¼æ¨¡å¼" in input_mode:
            try:
                if full_path.endswith(('.xlsx', '.xls')): df = pd.read_excel(full_path)
                elif full_path.endswith('.csv'): df = pd.read_csv(full_path)
                else:
                    with open(full_path, 'r', encoding='utf-8') as f: lines = [l.strip() for l in f.readlines() if l.strip()]
                    df = pd.DataFrame(lines, columns=['Content'])
                for index, row in df.iterrows():
                    row_str = " | ".join([f"{k}: {v}" for k, v in row.items() if pd.notna(v)])
                    raw_content_list.append(row_str)
            except Exception as e: return (f"âŒ è¡¨æ ¼è¯»å–å¤±è´¥: {str(e)}", [], "", f"é”™è¯¯: {str(e)}")
        else:
            novel_text = ""
            try:
                if full_path.endswith('.docx'):
                    if docx is None: return ("âŒ é”™è¯¯ï¼šéœ€å®‰è£… python-docx", [], "", "")
                    doc = docx.Document(full_path)
                    novel_text = "\n".join([para.text for para in doc.paragraphs])
                else:
                    with open(full_path, 'r', encoding='utf-8') as f: novel_text = f.read()
                
                # è‡ªåŠ¨åˆ†é•œ
                split_prompt = f"è¯·å°†ä»¥ä¸‹å°è¯´ç‰‡æ®µæ‹†è§£æˆå…·ä½“çš„ã€åˆ†é•œåˆ—è¡¨ã€‘...\n{novel_text[:3000]}"
                split_res, _ = self._call_qwen(api_key, model_id, "ä½ æ˜¯ä¸€ä¸ªåˆ†é•œæ‹†è§£å·¥å…·", split_prompt)
                raw_content_list = [line.strip() for line in split_res.split('\n') if line.strip()]
            except Exception as e: return (f"âŒ å°è¯´å¤„ç†å¤±è´¥: {str(e)}", [], "", f"é”™è¯¯: {str(e)}")

        system_instruction = self._build_system_prompt(style_tag, chars, enable_dialogue, enable_sfx, enable_camera_move)
        prompt_results = []
        print(f"ğŸ¬ HDD [{model_id}] å¼€å§‹ç”Ÿæˆï¼Œå…± {len(raw_content_list)} ä¸ªé•œå¤´...")

        for index, content in enumerate(raw_content_list):
            res_text, thought = self._call_qwen(api_key, model_id, system_instruction, content)
            prompt_results.append(res_text)
            if thought: full_thought_process.append(f"--- é•œå¤´ {index+1} ---\n{thought}")

        return ("\n\n".join(prompt_results), prompt_results, "\n\n".join(full_thought_process), "æˆåŠŸ")

    def _build_system_prompt(self, style, chars, show_dialogue, show_sfx, show_camera):
        char_rules = "\n".join([f"- å½“å‡ºç°åå­—ã€{name}ã€‘æ—¶ï¼Œå¿…é¡»æ›¿æ¢ä¸ºè§†è§‰æè¿°ï¼š{desc}" for name, desc in chars.items()])
        camera_instruction = "5. **ä¿ç•™è¿é•œ**: åŒ…å«æ¨æ‹‰æ‘‡ç§»æè¿°ã€‚" if show_camera else "5. **å»é™¤è¿é•œ**: å¿½ç•¥è¿é•œæœ¯è¯­ã€‚"
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ¨æ¼«åˆ†é•œè½¬æ¢åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·æä¾›çš„å‰§æƒ…/åˆ†é•œå†…å®¹ï¼Œè½¬åŒ–ä¸º Qwen-Image / Midjourney / Flux å¯ç›´æ¥ä½¿ç”¨çš„ä¸­æ–‡è‡ªç„¶è¯­è¨€æç¤ºè¯ï¼Œæç¤ºè¯ä¸å°‘äºåœ¨120-280å­—ã€‚
### å…¨å±€è®¾å®š
- é£æ ¼: {style}
- è§„åˆ™: ç»å¯¹å»äººååŒ–ï¼ˆæœ€ç»ˆç»™æˆ‘çš„æç¤ºè¯ä¸­å°±ç®—å«æœ‰äººåä¹Ÿå¾—æ˜¯â€œåå­—ï¼ˆå¤–è²Œæè¿°ï¼‰â€ï¼‰ã€‚ä¾‹å¦‚ï¼šå°æ˜ï¼ˆä¸€ä¸ªå¸…æ°”çš„å¹´è½»ç”·æ€§ï¼Œé»‘è‰²çŸ­å‘ï¼Œé»‘è‰²è€³é’‰ï¼Œå¤´é¡¶å‘†æ¯›ï¼Œèº«æå¼ºå£®ï¼Œå¸¸ç©¿çœŸç©ºé»‘é©¬ç”²ä¸ç´§èº«è¥¿è£¤ï¼Œè„–å­æˆ´æ¾å®é¢†å¸¦ï¼‰è¡¨æƒ…éš¾è¿‡çš„å¯¹ç€å·¦ä¾§è¯´è¯ã€‚
- æ˜ å°„è¡¨:
{char_rules}
- å†…å®¹æ§åˆ¶: {"åŒ…å«å°è¯" if show_dialogue else "ä¸åŒ…å«å°è¯"}ï¼Œ{"åŒ…å«éŸ³æ•ˆ" if show_sfx else "ä¸åŒ…å«éŸ³æ•ˆ"}
{camera_instruction}
- å…‰å½±: æ ¹æ®åˆ†é•œæè¿°æ’°å†™æˆå…·æœ‰æ•…äº‹æ°›å›´çš„å…‰å½±ï¼Œå¯ä»¥ä¾ç…§â€œé£æ ¼åŸºè°ƒè°ƒæ•´â€ï¼Œå¹¶ä¸”æ˜ç¡®è¡¨ç¤ºæ™šä¸Š/ç™½å¤©/é˜´å¤©ç­‰å¤©æ°”â€ã€‚
- åœºæ™¯: æ ¹æ®åˆ†é•œä¸Šä¸‹æ–‡ç†è§£ï¼Œæ¯æ®µéƒ½è¦åŠ ä¸Šåœºæ™¯ï¼Œåœºæ™¯å»ºç­‘é£æ ¼ä¾ç…§â€œé£æ ¼åŸºè°ƒâ€ã€‚
- é•œå¤´: æ ¹æ®åˆ†é•œä¸Šä¸‹æ–‡ç†è§£ï¼Œæ¯æ®µéƒ½è¦åŠ ä¸Šé•œå¤´æè¿°ï¼Œå¦‚ï¼šè„¸éƒ¨ç‰¹å†™é•œå¤´/å±€éƒ¨ç‰¹å†™é•œå¤´ï¼ˆæ˜ç¡®è¯´æ˜é‚£ä¸ªéƒ¨ä½ï¼‰/ä¸­æ™¯é•œå¤´/è¿‘æ™¯é•œå¤´/å…¨æ™¯/é±¼çœ¼é•œå¤´ç­‰ã€‚
- è§’åº¦: æ ¹æ®åˆ†é•œä¸Šä¸‹æ–‡ç†è§£ï¼Œæ¯æ®µéƒ½è¦åŠ ä¸Šè§’è‰²è§’åº¦ï¼Œå¦‚ä¸Šä¸€ä¸ªé•œå¤´æ˜¯æ­£é¢ï¼Œé‚£ä¹ˆä¸‹ä¸€ä¸ªé•œå¤´å°±å¾—æ˜¯ä¾§é¢æˆ–è€…ä¿¯è§†/ä»°è§†ç­‰å…¶å®ƒè§’åº¦çœ‹å‘å¦ä¸€è¾¹æˆ–è€…æŸä¸ªå¯¹è±¡ï¼Œä¸€ç›´ä¸€ä¸ªè§’åº¦ä¼šå¾ˆæ€ªï¼Œæ ¹æ®ä½ çš„ç†è§£ä»¥åŠå¯¹é•œå¤´çš„æŠŠæ¡æ¥å†³ç­–ã€‚
- æ‹æ‘„è§’åº¦: æ ¹æ®åˆ†é•œä¸Šä¸‹æ–‡ç†è§£ï¼Œé€‰æ‹©æ˜¯å¦åŠ ä¸Šæ‹æ‘„è§’åº¦æ¥åŠ å¼ºç”»é¢å™äº‹èƒ½åŠ›ï¼Œå¦‚ï¼šä¿¯è§†æ‹æ‘„/ä»°è§†æ‹æ‘„ç­‰ã€‚
- ä¸¥ç¦: ä¸æ˜¯ç‰¹æ®Šæƒ…å†µï¼Œè§’è‰²ä¸èƒ½çœ‹ç€é•œå¤´ï¼ˆéœ€è¦è¯´æ˜è§’è‰²çœ‹æŸä¸ªæ–¹å‘ï¼Œå¦åˆ™aiä¼šè‡ªå·±çœ‹å‘é•œå¤´ï¼‰ã€‚
è¦æ±‚ï¼š
1. æ¯ä¸€è¡Œåªè¾“å‡ºä¸€ä¸ªåˆ†é•œç”»é¢æè¿°ã€‚
2. åŒ…å«è§’è‰²åŠ¨ä½œã€ç¯å¢ƒã€å…‰å½±ç®€å•æè¿°ã€‚
3. å¿½ç•¥å¿ƒç†æå†™ï¼Œè½¬åŒ–ä¸ºè§†è§‰ç”»é¢ã€‚
4. æ ¼å¼ï¼šçº¯æ–‡æœ¬ï¼Œæ¯è¡Œä¸€ä¸ªé•œå¤´ï¼Œä¸è¦å¸¦åºå·ã€‚
ç›´æ¥è¾“å‡ºæç¤ºè¯ï¼Œä¸è¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹æˆ–è§£é‡Šã€‚
"""
        return prompt

    def _call_qwen(self, api_key, model_id, system_prompt, user_content):
        if not api_key: return "é”™è¯¯: ç¼ºå°‘APIå¯†é’¥", ""
        try:
            client = OpenAI(api_key=api_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
            resp = client.chat.completions.create(
                model=model_id,
                messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}]
            )
            content = resp.choices[0].message.content.strip()
            thought = ""
            try: thought = resp.choices[0].message.reasoning_content
            except: pass
            return content, thought
        except Exception as e: return f"APIé”™è¯¯: {str(e)}", ""


# ==============================================================================
# èŠ‚ç‚¹ 3: å›¾ç”Ÿè§†é¢‘æç¤ºè¯ (HDD_Image_to_Video_Prompt_Gen)
# ==============================================================================
class HDD_Image_to_Video_Prompt_Gen:
    def __init__(self): pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "enable_batch_mode": ("BOOLEAN", {"default": False, "label": "å¯ç”¨æ‰¹é‡æ¨¡å¼"}),
                "file_name": ("STRING", {"default": "è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¸Šä¼ æ–‡ä»¶...", "multiline": False, "label": "ä¸Šä¼ åˆ†é•œæ–‡ä»¶"}),
                "model_select": ([
                    "qwen3-vl-plus (æœ€æ–°æ­£å¼ç‰ˆ)", 
                    "qwen3-vl-plus-2025-12-19 (å¿«ç…§ç‰ˆæœ¬)"
                ], {"label": "AIæ¨¡å‹é€‰æ‹©"}),
                "api_key": ("STRING", {"multiline": False, "default": "", "label": "ğŸ”‘ é˜¿é‡Œäº‘APIå¯†é’¥"}), 
                "style_tag": (["ä¸­å¼ææ€–", "å¤ä»£è¨€æƒ…", "ç°ä»£éƒ½å¸‚", "å¤é£ä»™ä¾ ", "èµ›åšæœ‹å…‹", "æ—¥ç³»äºŒæ¬¡å…ƒ", "3DåŠ¨ç”»"], {"label": "è§†é¢‘é£æ ¼"}),
                
                # å¼ºåˆ¶ä¸­æ–‡æ ‡ç­¾
                "enable_reasoning": ("BOOLEAN", {"default": False, "label": "æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹"}),
                "enable_sfx": ("BOOLEAN", {"default": False, "label": "ç”ŸæˆéŸ³æ•ˆæç¤º"}),
                "enable_bgm": ("BOOLEAN", {"default": False, "label": "ç”ŸæˆBGMæç¤º"}),
                "enable_dialogue": ("BOOLEAN", {"default": False, "label": "ç”Ÿæˆå°è¯æç¤º"}),
                
                # æµ‹è¯•åŠŸèƒ½
                "enable_test_mode": ("BOOLEAN", {"default": False, "label": "ğŸ› ï¸ å¯ç”¨æµ‹è¯•æ¨¡å¼"}),
                "test_input_text": ("STRING", {"default": "æè¿°è¿™å¼ å›¾ç‰‡ï¼Ÿ", "multiline": True, "label": "æµ‹è¯•æé—®å†…å®¹"}),
            },
            "optional": {
                # å•å›¾æ¨¡å¼å‚æ•°
                "input_image": ("IMAGE", {"label": "è¾“å…¥å›¾ç‰‡ (å•å›¾æ¨¡å¼)"}),
                "shot_number": ("INT", {"default": 1, "min": 1, "max": 9999, "step": 1, "label": "é•œå¤´å· (å•å›¾æ¨¡å¼)"}),
                # æ‰¹é‡æ¨¡å¼å‚æ•°
                "image_directory": ("STRING", {"default": "/root/autodl-tmp/ComfyUI/output/my_project/", "multiline": False, "label": "å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„ (æ‰¹é‡æ¨¡å¼)"}),
            }
        }

    # ä¿®æ”¹ç‚¹ 1: å¢åŠ  INT è¾“å‡ºç±»å‹
    RETURN_TYPES = ("STRING", "LIST", "STRING", "STRING", "INT")
    # ä¿®æ”¹ç‚¹ 2: å¢åŠ  "é¢„ä¼°æ—¶é•¿" è¾“å‡ºåç§°
    RETURN_NAMES = ("è§†é¢‘æç¤ºè¯", "æç¤ºè¯åˆ—è¡¨", "AIæ€è€ƒè¿‡ç¨‹", "å¤„ç†ä¿¡æ¯", "é¢„ä¼°æ—¶é•¿")
    FUNCTION = "generate_video_prompt"
    CATEGORY = "HDD/Story"

    def generate_video_prompt(self, enable_batch_mode, file_name, model_select, api_key, style_tag, enable_reasoning, enable_sfx, enable_bgm, enable_dialogue, enable_test_mode, test_input_text, input_image=None, shot_number=1, image_directory=""):
        import base64
        from io import BytesIO
        from PIL import Image, ImageOps
        import numpy as np
        import torch

        if not api_key: return ("é”™è¯¯: ç¼ºå°‘APIå¯†é’¥", [], "", "é”™è¯¯: ç¼ºå°‘APIå¯†é’¥", 5)
        
        # æ¨¡å‹é€‰æ‹©
        model_id = "qwen3-vl-plus"
        if "2025-12-19" in model_select: model_id = "qwen3-vl-plus-2025-12-19"
        
        client = OpenAI(api_key=api_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
        
        # æ€è€ƒå‚æ•°é…ç½®
        extra_body = {}
        if enable_reasoning:
            extra_body = {"enable_thinking": True, "thinking_budget": 81920}

        def get_img_base64(img):
            buff = BytesIO()
            img.save(buff, format="JPEG")
            return base64.b64encode(buff.getvalue()).decode("utf-8")
        
        def tensor_to_pil(tensor):
            """å°†ComfyUIçš„IMAGE tensorè½¬æ¢ä¸ºPIL Image"""
            if tensor is None: return None
            # tensor shape: [batch, height, width, channels]
            if len(tensor.shape) == 4:
                tensor = tensor[0]  # å–ç¬¬ä¸€å¼ 
            # è½¬æ¢ä¸ºnumpyå¹¶ç¡®ä¿å€¼åœ¨[0,1]èŒƒå›´
            if tensor.max() > 1.0:
                tensor = tensor / 255.0
            numpy_image = (tensor.cpu().numpy() * 255).astype(np.uint8)
            return Image.fromarray(numpy_image)
        
        # è¾…åŠ©å‡½æ•°ï¼šè§£ææ—¶é•¿
        def parse_duration(text_content):
            try:
                # åŒ¹é… Duration: 5 æˆ– Duration: 10s ç­‰æ ¼å¼
                match = re.search(r"Duration:\s*(\d+)", text_content, re.IGNORECASE)
                if match:
                    val = int(match.group(1))
                    # é™åˆ¶åœ¨ 5-12 èŒƒå›´å†…ï¼Œé˜²æ­¢AIå¹»è§‰è¾“å‡ºå¤ªå¤§æˆ–å¤ªå°çš„æ•°
                    if val < 5: return 5
                    if val > 12: return 12
                    return val
            except:
                pass
            return 5 # é»˜è®¤å€¼

        # --- æµ‹è¯•æ¨¡å¼ ---
        if enable_test_mode and test_input_text.strip():
            print(f"ğŸ› ï¸ [å›¾ç”Ÿè§†é¢‘] æµ‹è¯•æ¨¡å¼: {model_id}")
            try:
                content_payload = [{"type": "text", "text": test_input_text}]
                if input_image is not None:
                    pil_img = tensor_to_pil(input_image)
                    if pil_img:
                        content_payload.insert(0, {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{get_img_base64(pil_img)}"}})
                
                resp = client.chat.completions.create(
                    model=model_id,
                    messages=[{"role": "user", "content": content_payload}],
                    extra_body=extra_body
                )
                
                thought = ""
                try: thought = resp.choices[0].message.reasoning_content
                except: pass
                
                # æµ‹è¯•æ¨¡å¼é»˜è®¤æ—¶é•¿è¿”å›5
                return (resp.choices[0].message.content, [resp.choices[0].message.content], f"æ€è€ƒè¿‡ç¨‹:\n{thought}", "æµ‹è¯•æ¨¡å¼å®Œæˆ", 5)
            except Exception as e: return (f"æµ‹è¯•é”™è¯¯: {str(e)}", [], "", f"æµ‹è¯•é”™è¯¯: {str(e)}", 5)

        # --- è¯»å–åˆ†é•œè¡¨æ ¼ ---
        input_dir = folder_paths.get_input_directory()
        full_path = os.path.join(input_dir, os.path.basename(file_name))
        if not os.path.exists(full_path): full_path = file_name 
        
        df = None
        try:
            if full_path.endswith(('.xlsx', '.xls')): df = pd.read_excel(full_path)
            elif full_path.endswith('.csv'): df = pd.read_csv(full_path)
            else: 
                with open(full_path, 'r', encoding='utf-8') as f: lines = [l.strip() for l in f.readlines() if l.strip()]
                df = pd.DataFrame(lines, columns=['Content'])
        except Exception as e: return (f"è¯»å–è¡¨æ ¼é”™è¯¯: {str(e)}", [], "", f"è¯»å–è¡¨æ ¼é”™è¯¯: {str(e)}", 5)
        
        if df is None or len(df) == 0:
            return ("é”™è¯¯: è¡¨æ ¼ä¸ºç©ºæˆ–è¯»å–å¤±è´¥", [], "", "é”™è¯¯: è¡¨æ ¼ä¸ºç©ºæˆ–è¯»å–å¤±è´¥", 5)

        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        has_audio_requirement = enable_sfx or enable_bgm or enable_dialogue
        
        sfx_instruction = "è¦æ±‚ç”ŸæˆéŸ³æ•ˆæç¤ºè¯ (SFX: ...)ã€‚æ³¨æ„ï¼šéŸ³æ•ˆä¸åŒ…æ‹¬å°è¯ï¼ŒåªåŒ…æ‹¬ç¯å¢ƒéŸ³ã€åŠ¨ä½œéŸ³ç­‰ã€‚" if enable_sfx else "ç¦æ­¢ç”Ÿæˆä»»ä½•éŸ³æ•ˆæè¿°ã€‚"
        bgm_instruction = "è¦æ±‚æ ¹æ®é•œå¤´å·å’Œå›¾ç‰‡çš„æ°›å›´æè¿°åˆé€‚çš„BGMã€‚ä¾‹å¦‚ï¼šå½“ç”»é¢æ˜¯ææ€–æ°›å›´æ—¶ï¼Œæè¿°ä¸º'æ‚¬ç–‘ææ€–çš„äºŒèƒ¡éŸ³ä¹'ï¼›å½“ç”»é¢æ˜¯ç´§å¼ æ°›å›´æ—¶ï¼Œæè¿°ä¸º'ç´§å¼ åˆºæ¿€çš„é¼“ç‚¹éŸ³ä¹'ç­‰ã€‚éœ€è¦æ ¹æ®ç”»é¢æ°›å›´å’Œå‰§æƒ…éœ€è¦é€‰æ‹©åˆé€‚çš„BGMç±»å‹å’Œé£æ ¼ã€‚" if enable_bgm else "ç¦æ­¢ç”Ÿæˆä»»ä½•èƒŒæ™¯éŸ³ä¹æˆ–BGMæè¿°ï¼Œå¹¶ä¸”åœ¨æœ€ç»ˆæç¤ºè¯æœ«å°¾å¦èµ·ä¸€è¡ŒåŠ å…¥æ²¡æœ‰ä»»ä½•èƒŒæ™¯éŸ³ä¹æˆ–BGMçš„æç¤ºè¯ã€‚"
        dialogue_instruction = "è¦æ±‚ç»“åˆé•œå·å†…å®¹å’Œå›¾ç‰‡å†…å®¹ç”Ÿæˆå°è¯æç¤ºã€‚åˆ†é•œè„šæœ¬ä¸­çš„å°è¯å¿…é¡»åŸå°ä¸åŠ¨åœ°ä½¿ç”¨ï¼Œä¸è¦ä¿®æ”¹å°è¯å†…å®¹ï¼Œä½†å¯ä»¥æ·»åŠ å£°çº¿æè¿°ï¼Œä¾‹å¦‚è¡¨æ ¼ä¸­å†™ç€'ç‹å¹´ï¼ˆä¸€ä¸ªé˜´æ²‰çš„é’å¹´ç”·æ€§å£°éŸ³ï¼‰ï¼šå¦‚æœç»™ä½ ä¸€ä¸ªæœºä¼š,æŠŠå®¶é‡Œé‚£ä½é»„è„¸å©†çš„å¤´æ¢æ‰...è¿™ä¸‰æ¬¾,ä½ ä¼šé€‰å“ªä¸€ä¸ª?'ä½ å°±å¯ä»¥æ•´åˆæˆ'ç‹å¹´ï¼ˆä¸€ä¸ªé˜´æ²‰çš„é’å¹´ç”·æ€§å£°éŸ³ï¼‰æ„¤æ€’çš„è¯´é“ï¼š...'ç­‰ã€‚éœ€è¦æ ¹æ®å›¾ç‰‡ä¸­çš„äººç‰©ç‰¹å¾å’Œåˆ†é•œå†…å®¹åˆ¤æ–­åˆé€‚çš„å£°çº¿æè¿°,å¹¶ä¸”æœ€ç»ˆçš„å°è¯ç»“æ„å¿…é¡»æ˜¯ï¼šå£°çº¿ï¼ˆåŒä¸€äººç‰©å›ºå®šï¼‰ï¼‹æƒ…ç»ªï¼ˆå˜é‡ï¼‰ï¼šå°è¯å†…å®¹ï¼ˆå˜é‡ï¼‰ã€‚" if enable_dialogue else "ç¦æ­¢ç”Ÿæˆä»»ä½•å°è¯ç›¸å…³å†…å®¹ã€‚"
        
        audio_section = f"""
éŸ³é¢‘è¦æ±‚ï¼š
{sfx_instruction}
{bgm_instruction}
{dialogue_instruction}
""" if has_audio_requirement else "éŸ³é¢‘è¦æ±‚ï¼šæ‰€æœ‰éŸ³é¢‘åŠŸèƒ½å‡å·²å…³é—­ï¼Œç¦æ­¢ç”Ÿæˆä»»ä½•éŸ³é¢‘ç›¸å…³å†…å®¹ï¼ˆåŒ…æ‹¬éŸ³æ•ˆã€BGMã€å°è¯ç­‰ï¼‰ã€‚"
        
        # ä¿®æ”¹ç‚¹ 3: æ›´æ–°è¾“å‡ºæ ¼å¼è¦æ±‚ï¼Œå¢åŠ  Duration
        output_format = f"""
è¾“å‡ºæ ¼å¼ï¼š
- Visual Prompt: (æè¿°ç”»é¢å†…å®¹ã€è¿é•œã€å…·ä½“çš„åŠ¨ä½œå¹…åº¦ï¼Œä¸­æ–‡)
- Duration: (æ ¹æ®ç”»é¢å†…å®¹çš„åŠ¨ä½œå¹…åº¦å’Œå°è¯é•¿åº¦ï¼Œæ¨æ–­æ‰€éœ€çš„è§†é¢‘æ—¶é•¿ã€‚å¿…é¡»æ˜¯ 5 åˆ° 12 ä¹‹é—´çš„æ•´æ•°ï¼Œå•ä½ç§’ã€‚ä¾‹å¦‚ï¼š5, 8, 12)
"""
        if has_audio_requirement:
            output_format += "- Audio Prompt: (åŒ…å«éŸ³æ•ˆ/BGM/å°è¯æè¿°ï¼Œæ ¹æ®ä¸Šè¿°è¦æ±‚ç”Ÿæˆ)\n"
        
        sys_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªAIè§†é¢‘æç¤ºè¯ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ã€è¾“å…¥å›¾ç‰‡ã€‘å’Œã€åˆ†é•œå‰§æœ¬ã€‘ï¼Œç”Ÿæˆç”Ÿæˆè§†é¢‘æ¨¡å‹ (å¦‚ Kling, Runway, Vidu) æ‰€éœ€çš„ä¸­æ–‡åŠ¨æ•ˆæç¤ºè¯å’Œæ—¶é•¿é¢„ä¼°ã€‚
é£æ ¼: {style_tag}
{audio_section}
è¯·ä»”ç»†è§‚å¯Ÿå›¾ç‰‡ä¸­çš„äººç‰©ã€ç¯å¢ƒã€è‰²è°ƒï¼Œå¹¶ç»“åˆåˆ†é•œå‰§æœ¬ä¸­çš„åŠ¨ä½œæè¿°ï¼Œä¸éœ€è¦å¤šä½™çš„è¯´æ˜æ–‡å­—ï¼Œç›´æ¥ç»™æˆ‘æç¤ºè¯ï¼Œæ–¹ä¾¿ç²˜è´´å¤åˆ¶ã€‚
{output_format}
"""

        # --- å•å›¾æ¨¡å¼ ---
        if not enable_batch_mode:
            if input_image is None:
                return ("é”™è¯¯: å•å›¾æ¨¡å¼éœ€è¦è¾“å…¥å›¾ç‰‡", [], "", "é”™è¯¯: å•å›¾æ¨¡å¼éœ€è¦è¾“å…¥å›¾ç‰‡", 5)
            
            # è½¬æ¢tensorä¸ºPIL Image
            pil_image = tensor_to_pil(input_image)
            if pil_image is None:
                return ("é”™è¯¯: å›¾ç‰‡è½¬æ¢å¤±è´¥", [], "", "é”™è¯¯: å›¾ç‰‡è½¬æ¢å¤±è´¥", 5)
            
            # è·å–å¯¹åº”é•œå¤´å·çš„åˆ†é•œå†…å®¹
            shot_idx = shot_number - 1  # é•œå¤´å·ä»1å¼€å§‹ï¼Œç´¢å¼•ä»0å¼€å§‹
            if shot_idx < 0 or shot_idx >= len(df):
                return (f"é”™è¯¯: é•œå¤´å· {shot_number} è¶…å‡ºèŒƒå›´ (è¡¨æ ¼å…± {len(df)} è¡Œ)", [], "", f"é”™è¯¯: é•œå¤´å·è¶…å‡ºèŒƒå›´", 5)
            
            row_data = df.iloc[shot_idx]
            story_content = " | ".join([f"{k}: {v}" for k, v in row_data.items() if pd.notna(v)])
            
            try:
                img_b64 = get_img_base64(pil_image)
                resp = client.chat.completions.create(
                    model=model_id,
                    messages=[
                        {"role": "system", "content": sys_prompt}, 
                        {"role": "user", "content": [
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_b64}"}},
                            {"type": "text", "text": f"åˆ†é•œå‰§æœ¬ (é•œå¤´{shot_number}): {story_content}"}
                        ]} 
                    ],
                    extra_body=extra_body
                )
                
                content = resp.choices[0].message.content
                thought = ""
                try: thought = resp.choices[0].message.reasoning_content
                except: pass
                
                # ä¿®æ”¹ç‚¹ 4: è§£æå•å›¾æ—¶é•¿
                duration_val = parse_duration(content)
                
                return (content, [content], thought, f"æˆåŠŸç”Ÿæˆé•œå¤´ {shot_number} çš„æç¤ºè¯ (æ—¶é•¿: {duration_val}s)", duration_val)
            except Exception as e: 
                return (f"APIé”™è¯¯: {str(e)}", [], "", f"APIé”™è¯¯: {str(e)}", 5)

        # --- æ‰¹é‡æ¨¡å¼ ---
        else:
            if not image_directory or not os.path.exists(image_directory):
                return ("é”™è¯¯: æ‰¹é‡æ¨¡å¼éœ€è¦æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„", [], "", "é”™è¯¯: æ‰¹é‡æ¨¡å¼éœ€è¦æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„", 5)
            
            # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
            image_files = sorted([f for f in os.listdir(image_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.webp'))])
            if len(image_files) == 0:
                return ("é”™è¯¯: å›¾ç‰‡æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶", [], "", "é”™è¯¯: å›¾ç‰‡æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶", 5)
            
            # æ£€æŸ¥æ•°é‡åŒ¹é…
            table_rows = len(df)
            image_count = len(image_files)
            
            if table_rows != image_count:
                return (
                    f"é”™è¯¯: è¡¨æ ¼è¡Œæ•° ({table_rows}) ä¸å›¾ç‰‡æ•°é‡ ({image_count}) ä¸åŒ¹é…",
                    [],
                    "",
                    f"é”™è¯¯: è¡¨æ ¼è¡Œæ•° ({table_rows}) ä¸å›¾ç‰‡æ•°é‡ ({image_count}) ä¸åŒ¹é…ï¼Œè¯·ç¡®ä¿æ•°é‡ä¸€è‡´",
                    5
                )
            
            print(f"ğŸ¬ HDD [{model_id}] æ‰¹é‡æ¨¡å¼: å¼€å§‹å¤„ç† {table_rows} ä¸ªé•œå¤´...")
            
            all_prompts = []
            all_thoughts = []
            all_durations = [] # æ–°å¢æ—¶é•¿åˆ—è¡¨
            error_count = 0
            
            # é€ä¸ªå¤„ç†æ¯ä¸ªé•œå¤´
            for idx in range(table_rows):
                try:
                    # è¯»å–å›¾ç‰‡
                    img_path = os.path.join(image_directory, image_files[idx])
                    pil_image = Image.open(img_path)
                    pil_image = ImageOps.exif_transpose(pil_image)
                    if pil_image.mode != 'RGB':
                        pil_image = pil_image.convert('RGB')
                    
                    # è·å–åˆ†é•œå†…å®¹
                    row_data = df.iloc[idx]
                    story_content = " | ".join([f"{k}: {v}" for k, v in row_data.items() if pd.notna(v)])
                    
                    # è°ƒç”¨AI
                    img_b64 = get_img_base64(pil_image)
                    resp = client.chat.completions.create(
                        model=model_id,
                        messages=[
                            {"role": "system", "content": sys_prompt}, 
                            {"role": "user", "content": [
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_b64}"}},
                                {"type": "text", "text": f"åˆ†é•œå‰§æœ¬ (é•œå¤´{idx+1}): {story_content}"}
                            ]} 
                        ],
                        extra_body=extra_body
                    )
                    
                    content = resp.choices[0].message.content
                    all_prompts.append(content)
                    
                    # è§£ææ‰¹é‡ä¸­çš„æ—¶é•¿
                    d_val = parse_duration(content)
                    all_durations.append(d_val)
                    
                    thought = ""
                    try: thought = resp.choices[0].message.reasoning_content
                    except: pass
                    if thought:
                        all_thoughts.append(f"--- é•œå¤´ {idx+1} ---\n{thought}")
                    
                    print(f"âœ… é•œå¤´ {idx+1}/{table_rows} å®Œæˆ (æ—¶é•¿: {d_val}s)")
                    
                except Exception as e:
                    error_count += 1
                    error_msg = f"é•œå¤´ {idx+1} å¤„ç†å¤±è´¥: {str(e)}"
                    all_prompts.append(f"é”™è¯¯: {error_msg}")
                    all_durations.append(5) # é”™è¯¯é»˜è®¤æ—¶é•¿
                    print(f"âŒ {error_msg}")
            
            # æ±‡æ€»ç»“æœ
            combined_thought = "\n\n".join(all_thoughts) if all_thoughts else "æ— æ€è€ƒè¿‡ç¨‹"
            combined_prompt = "\n\n---\n\n".join(all_prompts)
            info_msg = f"æ‰¹é‡å¤„ç†å®Œæˆ: æˆåŠŸ {table_rows - error_count}/{table_rows} ä¸ªé•œå¤´"
            if error_count > 0:
                info_msg += f"ï¼Œå¤±è´¥ {error_count} ä¸ª"
            
            # æ³¨æ„ï¼šæœ€åè¿”å› all_durations (INT LIST)
            return (combined_prompt, all_prompts, combined_thought, info_msg, all_durations)


# ==============================================================================
# èŠ‚ç‚¹ 4: å‰§æœ¬è½¬åˆ†é•œè¡¨æ ¼ (HDD_Script_to_Storyboard_Table)
# ==============================================================================
class HDD_Script_to_Storyboard_Table:
    def __init__(self): pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "file_name": ("STRING", {"default": "è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¸Šä¼ æ–‡ä»¶...", "multiline": False, "label": "ä¸Šä¼ å‰§æœ¬/åˆ†é•œæ–‡ä»¶"}),
                "input_mode": (["æ–‡æœ¬å‰§æœ¬æ¨¡å¼ (Txt/Word - è‡ªåŠ¨åˆ†é•œ)", "å·²æœ‰åˆ†é•œè¡¨æ ¼æ¨¡å¼ (Excel/CSV - æ ‡å‡†åŒ–æ•´ç†)"], {"label": "è¾“å…¥æ¨¡å¼é€‰æ‹©"}),
                "model_select": ([
                    "qwen3-max (æœ€æ–°æ­£å¼ç‰ˆ)", 
                    "qwen3-max-preview (æ€è€ƒæ¨¡å¼)", 
                    "qwen3-max-2025-09-23 (å¿«ç…§ç‰ˆæœ¬)"
                ], {"label": "AIæ¨¡å‹é€‰æ‹©"}),
                "api_key": ("STRING", {"multiline": False, "default": "", "label": "ğŸ”‘ é˜¿é‡Œäº‘APIå¯†é’¥"}),
                "save_path": ("STRING", {"default": "", "multiline": False, "label": "ä¿å­˜è·¯å¾„ (ç•™ç©ºä½¿ç”¨é»˜è®¤è¾“å‡ºç›®å½•)"}),
                "output_filename": ("STRING", {"default": "åˆ†é•œè¡¨æ ¼_è¾“å‡º.xlsx", "multiline": False, "label": "è¾“å‡ºæ–‡ä»¶å"}),
                
                # æµ‹è¯•åŠŸèƒ½
                "enable_test_mode": ("BOOLEAN", {"default": False, "label": "ğŸ› ï¸ å¯ç”¨æµ‹è¯•æ¨¡å¼"}),
                "test_input_text": ("STRING", {"default": "ä½ æ˜¯è°ï¼Ÿ", "multiline": True, "label": "æµ‹è¯•æé—®å†…å®¹"}),
            }
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("è¡¨æ ¼æ–‡ä»¶è·¯å¾„", "è¡¨æ ¼å†…å®¹é¢„è§ˆ")
    FUNCTION = "convert_to_storyboard_table"
    CATEGORY = "HDD/Story"

    def convert_to_storyboard_table(self, file_name, input_mode, model_select, api_key, save_path, output_filename, enable_test_mode, test_input_text):
        if not api_key: return ("", "é”™è¯¯: ç¼ºå°‘APIå¯†é’¥")
        
        # æ¨¡å‹IDå¤„ç†
        model_id = "qwen3-max"
        if "preview" in model_select: model_id = "qwen3-max-preview"
        elif "2025-09-23" in model_select: model_id = "qwen3-max-2025-09-23"

        client = OpenAI(api_key=api_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")

        # --- æµ‹è¯•æ¨¡å¼ ---
        if enable_test_mode and test_input_text.strip():
            try:
                print(f"ğŸ› ï¸ [åˆ†é•œè¡¨æ ¼] æµ‹è¯•æ¨¡å¼: {model_id}")
                resp = client.chat.completions.create(model=model_id, messages=[{"role": "user", "content": test_input_text}])
                return ("æµ‹è¯•æ¨¡å¼", resp.choices[0].message.content)
            except Exception as e: return ("", f"æµ‹è¯•é”™è¯¯: {str(e)}")

        # --- è¯»å–è¾“å…¥æ–‡ä»¶ ---
        input_dir = folder_paths.get_input_directory()
        full_path = os.path.join(input_dir, os.path.basename(file_name))
        if not os.path.exists(full_path): full_path = file_name

        input_content = ""
        try:
            if full_path.endswith(('.xlsx', '.xls', '.csv')):
                if full_path.endswith('.csv'): df_input = pd.read_csv(full_path)
                else: df_input = pd.read_excel(full_path)
                input_content = df_input.to_string()
            elif full_path.endswith('.docx'):
                if docx is None: return ("", "é”™è¯¯: éœ€å®‰è£…python-docxåº“")
                doc = docx.Document(full_path)
                input_content = "\n".join([p.text for p in doc.paragraphs])
            else:
                with open(full_path, 'r', encoding='utf-8') as f: input_content = f.read()
        except Exception as e: return ("", f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")

        # --- æ„å»ºAIæç¤ºè¯ ---
        if "æ–‡æœ¬å‰§æœ¬" in input_mode:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åˆ†é•œè¡¨æ ¼ç”Ÿæˆä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†æ–‡æœ¬å‰§æœ¬è½¬æ¢ä¸ºæ ‡å‡†åŒ–çš„åˆ†é•œè¡¨æ ¼ã€‚

è¾“å‡ºè¦æ±‚ï¼š
1. å¿…é¡»è¾“å‡ºæ ‡å‡†çš„JSONæ•°ç»„æ ¼å¼ï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€ä¸ªé•œå¤´
2. æ¯ä¸ªé•œå¤´å¿…é¡»åŒ…å«ä»¥ä¸‹9ä¸ªå­—æ®µï¼ˆå­—æ®µåå¿…é¡»å®Œå…¨ä¸€è‡´ï¼‰ï¼š
   - "é•œå·": æ•°å­—ï¼Œä»1å¼€å§‹é€’å¢
   - "é˜¶æ®µ": å¦‚"äº’åŠ¨å¼€åœº"ã€"è½¬åœº"ã€"åŠ¨æœºé“ºå«"ã€"é«˜æ½®"ã€"ç»“å°¾"ç­‰
   - "å‡ºåœºè§’è‰²": è¯¥é•œå¤´ä¸­å‡ºç°çš„è§’è‰²åç§°ï¼Œå¤šä¸ªè§’è‰²ç”¨é€—å·åˆ†éš”ï¼Œå¹¶ä¸”è§’è‰²éœ€è¦å¢åŠ å£°çº¿æè¿°
   - "åœºæ™¯": åœºæ™¯æè¿°ï¼Œå¦‚"ä¸€ä¸ªé˜´æ£®ææ€–çš„å¤ä»£ä¹¦æˆ¿"ã€"ä¸€ä¸ªç™½å¤©çš„å¤ä»£è¡—é“"ç­‰
   - "é•œå¤´": é•œå¤´ç±»å‹ï¼Œå¦‚"å•äººä¸­æ™¯é•œå¤´"ã€"å•äººä¾§é¢è„¸éƒ¨ç‰¹å†™"ã€"åŒäººæ­£åæ‰“å¯¹è¯é•œå¤´"ç­‰
   - "ç”»é¢æè¿°": è¯¦ç»†çš„ç”»é¢è§†è§‰æè¿°
   - "è¿é•œ/åŠ¨æ•ˆ": é•œå¤´è¿åŠ¨æˆ–ç‰¹æ•ˆæè¿°ï¼Œå¦‚"é•œå¤´æ¨è¿‘"ã€"é•œå¤´æ‹‰è¿œ"ç­‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™å¡«ç©ºç€
   - "éŸ³æ•ˆ/BGM": éŸ³æ•ˆæˆ–èƒŒæ™¯éŸ³ä¹æè¿°ï¼Œå¦‚"æ²‰é—·çš„å¿ƒè·³å£°"ç­‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ç©ºç€
   - "å°è¯": è¯¥é•œå¤´çš„å¯¹è¯å†…å®¹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ç©ºç€

3. è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
[
  {
    "é•œå·": 1,
    "é˜¶æ®µ": "äº’åŠ¨å¼€åœº",
    "å‡ºåœºè§’è‰²": "ä½ çš„2Då½¢è±¡ï¼ˆä¸€ä¸ªé˜´æ²‰çš„é’å¹´ç”·æ€§å£°éŸ³ï¼‰",
    "åœºæ™¯": "ä¸€ä¸ªé˜´æ£®ææ€–çš„å¤ä»£ä¹¦æˆ¿",
    "é•œå¤´": "å•äººä¸­æ™¯é•œå¤´",
    "ç”»é¢æè¿°": "ã€ä½ çš„2Då½¢è±¡ã€‘ ä¸­è¿‘æ™¯ã€‚ä½ é¢å‰çš„æ¶å­ä¸Šæ‘†ç€ä¸‰é¢—é£æ ¼è¿¥å¼‚çš„ç»ç¾å¥³æ€§å¤´é¢…(é—­çœ¼)ã€‚ä½ çš„æ‰‹åœ¨ä¸Šæ–¹æ‚¬åœã€‚",
    "è¿é•œ/åŠ¨æ•ˆ": "é•œå¤´æ¨è¿‘",
    "éŸ³æ•ˆ/BGM": "æ²‰é—·çš„å¿ƒè·³å£°",
    "å°è¯": "ç‹æ˜ï¼ˆä¸€ä¸ªé˜´æ²‰çš„é’å¹´ç”·æ€§å£°éŸ³ï¼‰ï¼šå¦‚æœç»™ä½ ä¸€ä¸ªæœºä¼š,æŠŠå®¶é‡Œé‚£ä½é»„è„¸å©†çš„å¤´æ¢æ‰...è¿™ä¸‰æ¬¾,ä½ ä¼šé€‰å“ªä¸€ä¸ª?"
  }
]

4. åªè¾“å‡ºJSONæ•°ç»„ï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–æ–‡å­—æˆ–Markdownæ ‡è®°ã€‚"""
            
            user_prompt = f"è¯·å°†ä»¥ä¸‹æ–‡æœ¬å‰§æœ¬è½¬æ¢ä¸ºæ ‡å‡†åˆ†é•œè¡¨æ ¼ï¼š\n\n{input_content[:20000]}"
        else:
            # å·²æœ‰åˆ†é•œè¡¨æ ¼æ¨¡å¼ - æ ‡å‡†åŒ–æ•´ç†
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åˆ†é•œè¡¨æ ¼æ ‡å‡†åŒ–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†å·²æœ‰çš„åˆ†é•œè¡¨æ ¼æ•´ç†æˆæ ‡å‡†æ ¼å¼ã€‚

è¾“å‡ºè¦æ±‚ï¼š
1. å¿…é¡»è¾“å‡ºæ ‡å‡†çš„JSONæ•°ç»„æ ¼å¼ï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€ä¸ªé•œå¤´
2. æ¯ä¸ªé•œå¤´å¿…é¡»åŒ…å«ä»¥ä¸‹9ä¸ªå­—æ®µï¼ˆå­—æ®µåå¿…é¡»å®Œå…¨ä¸€è‡´ï¼‰ï¼š
   - "é•œå·": æ•°å­—ï¼Œä»1å¼€å§‹é€’å¢
   - "é˜¶æ®µ": å¦‚"äº’åŠ¨å¼€åœº"ã€"è½¬åœº"ã€"åŠ¨æœºé“ºå«"ã€"é«˜æ½®"ã€"ç»“å°¾"ç­‰
   - "å‡ºåœºè§’è‰²": è¯¥é•œå¤´ä¸­å‡ºç°çš„è§’è‰²åç§°ï¼Œå¤šä¸ªè§’è‰²ç”¨é€—å·åˆ†éš”
   - "åœºæ™¯": åœºæ™¯æè¿°
   - "é•œå¤´": é•œå¤´ç±»å‹æè¿°
   - "ç”»é¢æè¿°": è¯¦ç»†çš„ç”»é¢è§†è§‰æè¿°
   - "è¿é•œ/åŠ¨æ•ˆ": é•œå¤´è¿åŠ¨æˆ–ç‰¹æ•ˆæè¿°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ç©ºç€
   - "éŸ³æ•ˆ/BGM": éŸ³æ•ˆæˆ–èƒŒæ™¯éŸ³ä¹æè¿°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ç©ºç€
   - "å°è¯": è¯¥é•œå¤´çš„å¯¹è¯å†…å®¹ï¼Œå¦‚æœæ²¡æœ‰åˆ™å¡«ç©ºç€

3. å¦‚æœè¾“å…¥è¡¨æ ¼ä¸­æŸäº›å­—æ®µç¼ºå¤±ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡åˆç†æ¨æ–­å¡«å……
4. åªè¾“å‡ºJSONæ•°ç»„ï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–æ–‡å­—æˆ–Markdownæ ‡è®°ã€‚"""
            
            user_prompt = f"è¯·å°†ä»¥ä¸‹åˆ†é•œè¡¨æ ¼æ ‡å‡†åŒ–æ•´ç†ï¼š\n\n{input_content[:20000]}"

        # --- è°ƒç”¨AIç”Ÿæˆåˆ†é•œè¡¨æ ¼ ---
        try:
            print(f"ğŸ¬ HDD [{model_id}] å¼€å§‹ç”Ÿæˆåˆ†é•œè¡¨æ ¼...")
            resp = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            )
            
            ai_output = resp.choices[0].message.content.strip()
            
            # æ¸…ç†JSONå­—ç¬¦ä¸²
            json_start = ai_output.find('[')
            json_end = ai_output.rfind(']')
            if json_start == -1 or json_end == -1:
                return ("", f"AIè¾“å‡ºæ ¼å¼é”™è¯¯ï¼Œæœªæ‰¾åˆ°JSONæ•°ç»„\n\nåŸå§‹è¾“å‡º:\n{ai_output}")
            
            json_str = ai_output[json_start:json_end+1]
            storyboard_data = json.loads(json_str)
            
            # --- è½¬æ¢ä¸ºDataFrameå¹¶ä¿å­˜ ---
            df = pd.DataFrame(storyboard_data)
            
            # ç¡®ä¿åˆ—é¡ºåºæ­£ç¡®
            expected_columns = ["é•œå·", "é˜¶æ®µ", "å‡ºåœºè§’è‰²", "åœºæ™¯", "é•œå¤´", "ç”»é¢æè¿°", "è¿é•œ/åŠ¨æ•ˆ", "éŸ³æ•ˆ/BGM", "å°è¯"]
            for col in expected_columns:
                if col not in df.columns:
                    df[col] = "æ— "
            df = df[expected_columns]
            
            # ç¡®å®šä¿å­˜è·¯å¾„
            if save_path and save_path.strip():
                # ä½¿ç”¨è‡ªå®šä¹‰è·¯å¾„
                custom_path = save_path.strip()
                if os.path.isdir(custom_path):
                    # å¦‚æœæ˜¯ç›®å½•ï¼Œæ‹¼æ¥æ–‡ä»¶å
                    if not output_filename.endswith('.xlsx'):
                        output_filename = output_filename.replace('.csv', '.xlsx').replace('.xls', '.xlsx')
                        if not output_filename.endswith('.xlsx'):
                            output_filename += '.xlsx'
                    import datetime
                    if output_filename == "åˆ†é•œè¡¨æ ¼_è¾“å‡º.xlsx" or not any(char.isdigit() for char in output_filename):
                        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                        base_name = output_filename.replace('.xlsx', '')
                        output_filename = f"{base_name}_{timestamp}.xlsx"
                    output_path = os.path.join(custom_path, output_filename)
                else:
                    # å¦‚æœæ˜¯å®Œæ•´æ–‡ä»¶è·¯å¾„
                    if not custom_path.endswith('.xlsx'):
                        custom_path = custom_path.replace('.csv', '.xlsx').replace('.xls', '.xlsx')
                        if not custom_path.endswith('.xlsx'):
                            custom_path += '.xlsx'
                    output_path = custom_path
                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    output_dir = os.path.dirname(output_path)
                    if output_dir and not os.path.exists(output_dir):
                        os.makedirs(output_dir, exist_ok=True)
            else:
                # ä½¿ç”¨é»˜è®¤è¾“å‡ºç›®å½•
                output_dir = folder_paths.get_output_directory()
                if not output_filename.endswith('.xlsx'):
                    output_filename = output_filename.replace('.csv', '.xlsx').replace('.xls', '.xlsx')
                    if not output_filename.endswith('.xlsx'):
                        output_filename += '.xlsx'
                
                # å¦‚æœæ–‡ä»¶åä¸åŒ…å«æ—¶é—´æˆ³ï¼Œæ·»åŠ æ—¶é—´æˆ³é¿å…è¦†ç›–
                import datetime
                if output_filename == "åˆ†é•œè¡¨æ ¼_è¾“å‡º.xlsx" or not any(char.isdigit() for char in output_filename):
                    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                    base_name = output_filename.replace('.xlsx', '')
                    output_filename = f"{base_name}_{timestamp}.xlsx"
                
                output_path = os.path.join(output_dir, output_filename)
            
            df.to_excel(output_path, index=False, engine='openpyxl')
            
            # ç”Ÿæˆé¢„è§ˆæ–‡æœ¬
            preview_text = f"âœ… æˆåŠŸç”Ÿæˆ {len(df)} ä¸ªé•œå¤´\n\n"
            preview_text += "è¡¨æ ¼é¢„è§ˆï¼ˆå‰5è¡Œï¼‰ï¼š\n"
            preview_text += df.head().to_string(index=False)
            
            print(f"âœ… åˆ†é•œè¡¨æ ¼å·²ä¿å­˜: {output_path}")
            return (output_path, preview_text)
            
        except json.JSONDecodeError as e:
            return ("", f"JSONè§£æé”™è¯¯: {str(e)}\n\nAIè¾“å‡º:\n{ai_output[:500]}")
        except Exception as e:
            return ("", f"å¤„ç†é”™è¯¯: {str(e)}")